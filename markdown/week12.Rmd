---
title: "PSY8960 Week 12 NLP"
author: "Vivien Lee"
date: "`r format(Sys.Date())`"
output: 
  html_document:
    df_print: paged
knit: (function(inputFile, encoding) {
    rmarkdown::render(inputFile, encoding = encoding, output_dir = "../out/")
  })    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Script Settings and Resources
```{r}
# Importing relevant libraries 
library(tidyverse)
library(httr)
library(rvest)

library(tm)
library(tidytext)
library(qdap)
library(textstem)

library(RWeka)
library(doParallel)
library(ldatuning)

library(topicmodels)
library(wordcloud)
```
\
 
# Data Import and Cleaning

### Data Creation through webscraping
```{r echo = FALSE}
# # Web Scraping from old IO Psychology subreddit 
# 
# ## Creating tibble to store response from get request, setting initial URL and counter
# responses_tbl = tibble() 
# get_url = "https://old.reddit.com/r/IOPsychology/"
# counter = 1 
# 
# ## This is a while-loop goes through all visible pages in the io subreddit 
# ### I initially set it to 100 pages but ran into an error at page 40 because 
# ### there are only 40 pages right now, so I set 40 for the while loop 
# 
# while(counter <= 40){
#   response = content(GET(get_url, user_agent("UMN Student lee02903@umn.edu")), as = "text")
#   responses_tbl = bind_rows(responses_tbl, tibble(response)) # storing get response to tibble
#   # print(paste(counter, "Just received data from", get_url))
#   
#   next_url = read_html(response) %>% html_elements("span.next-button a") %>% html_attr("href")
#   get_url = next_url # Setting URL for next iteration
#   counter = counter + 1 # Incrementing counter for while loop
#   
#   Sys.sleep(2) # Pause to conform to rate limit
# }
```

```{r echo = FALSE}
# # Creating a function "get_info" that gets three things:
# # 1) post title, 2) num of upvotes for each page, and 3) time, not required but added for me to check that I included at least posts from the past year

# get_info = function(single_page){
#   single_page = read_html(single_page)
#   xpath_post = "//div[contains(@class, 'odd') or contains(@class, 'even')]//a[contains(@class, 'title may-blank')]"
#   xpath_upvotes = "//div[contains(@class, 'odd') or contains(@class, 'even')]//div[@class = 'score unvoted']"
#   
#   post = html_elements(single_page, xpath = xpath_post) %>% html_text()
#   upvotes = html_elements(single_page, xpath = xpath_upvotes) %>% 
#     html_text() %>% 
#     as.numeric() 
#   
#   # Added for myself  to see the post date
#   time =  html_elements(single_page, "time:nth-child(1)") %>% html_text() 
#   
#   io_tbl = tibble(time = time[-1], post, upvotes)
#   return(io_tbl)
# }
```

```{r echo = FALSE}
# # Outputting a list of posts containing a separate tibble for each page
# posts_ls = lapply(responses_tbl$response, get_info)
# 
# # Collapsing all tibbles in the list to form one giant tibble
# week12_tbl =  bind_rows(posts_ls) %>% select(-time)
# 
# # Saving scraped dataset as week12_tbl.csv
# write_csv(week12_tbl, "../data/week12_tbl.csv")
```

\n

### Importing scraped data 
```{r import}
# Importing saved data 
week12_tbl = read_csv("../data/week12_tbl.csv")
```

### Creating and Cleaning Text Corpus using NLP
```{r creating_corpus}
# Creating a volatile corpus 
io_corpus_original = VCorpus(VectorSource(week12_tbl$post))
```

```{r cleaning_corpus}
# Cleaning corpus 
## The choice of sequence of pre-processing steps depended on what each function does. For instance, replace_contraction only works on lower case text. Therefore, str_to_lower() was used before. 

## Creating custom stopword list to remove words related to IO psychology and words like discussion and biweekly
io_stopwords = c("io psychology", "io", "io psych", "io psyc",
                 "riopsychology", "iopsychology", "psychology", "psychologist",
                 "psych")
custom_stopwords = c(stopwords("en"), io_stopwords)

## Begin actual cleaning
io_corpus = io_corpus_original %>%
  # Two steps are 
  # This step is added because reddit apostrophes look weird and don't match the ones in the contractions dictionary
  tm_map(content_transformer(str_replace_all), pattern = "’", replacement = "'") %>%
  # This step is added because my DTM has terms with weird punctuations that were not accounted for by removePunctuation
  tm_map(content_transformer(str_replace_all), pattern = "—|“|”|‘", replacement = "") %>%
  # This step was performed to replace any abbreviations before converting text to lower case because the abbreviation library is case sensitive 
  tm_map(content_transformer(replace_abbreviation)) %>% 
  tm_map(content_transformer(replace_contraction)) %>% 
  tm_map(content_transformer(str_to_lower)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, custom_stopwords) %>%
  tm_map(stripWhitespace) %>% 
  # This step is added to remove leading and ending spaces
  tm_map(content_transformer(trimws)) %>% 
  # This step is added because instructions require a "lemmatized" corpus
  tm_map(content_transformer(lemmatize_strings))
```


#### Creating function "compare_them" to compare individual post titles in the corpus before and after cleaning
```{r compare_corpus}
# Writing compare_them() function 
## input: io_corpus_original and io_corpus
compare_them = function(corpus1, corpus2){
  select_index = sample(1:length(io_corpus$content), 1)
  original_row = corpus1[[select_index]]$content
  cleaned_row = corpus2[[select_index]]$content
  return(data.frame(original_title = original_row,
                   cleaned_title = cleaned_row))
}
compare_them(io_corpus_original, io_corpus)
```


### Create Bigram document-term matrix 

* I first created a function called "bigram_filter" to filter out empty posts because their corresponding row in the document-term matrix will just be zeroes. Then, to create bigram document-term matrix, I  built a cutsom tokenizer to include only unigrams and bigrams. To reduce sparsity in the slim document-term matrix, I used the "removeSparseTerm()" function and set multiple sparsity values until I got one that was close to an n:k ratio that's close to 2:1 and 3:1 by dividing number of rows by the number of columns in the document-term matrix. 

```{r filter_posts}

## This functinon KEEPS the posts we want
## I created this because when trying to use the FindTopicsNumber function, 
## it threw an error saying some of my documents have 0 frequency across all bigrams which led me to build this function. I did not build this into my pre-processing pipeline because this would mess up the order of post for cleaned vs. original corpora.

bigram_filter = function(x){
  bool = nchar(stripWhitespace(x$content)[[1]]) > 0 
  # & str_count((x$content)[[1]], "\\S+") >= 2
  return(bool)
}

# This returns a logical vector showing whether they were filtered out which could 
# be used for matching upvotes later
post_retained = sapply(io_corpus, bigram_filter)
```


```{r create_dtm}
# Creating Bigram DTM 

## Creating bigram tokenizer using Weka
bigram_Tokenizer <- function(x) { 
  NGramTokenizer(x, Weka_control(min=1, max=2))
  }

## Creating bigram DTM 
io_dtm = io_corpus %>% 
  tm_filter(bigram_filter) %>% # removing empty posts, there are 3; so total doc number went from 978 to 975
  DocumentTermMatrix(control=list(tokenize = bigram_Tokenizer)) 

# Setting sparse = 0.997, the n:k ratio is about 2.1:1
io_slim_dtm = removeSparseTerms(io_dtm, sparse = 0.997) 
```

\

# Analysis

### Building topic models 

#### 1. Finding optimal number of topics 

* Based on the graph below,  k between 6 and 8 topics appear to strike a balance between all four metrics,  Griffiths (2004) and Deveaud (2014) are reasonably maximized, whereas Arun (2010) and Cao & Juan (2009) are reasonably minimized. Because k = 6 yielded more interpretable topic groupings, therefore, I based the rest of my analyses and responses on a 6-topic model. I also set seed for reproducibility.

```{r lda_number}
# Finding optimal number of lda topics; adopted code from slide 25

## Turning on parallelization
local_cluster = makeCluster(detectCores() - 1)   
registerDoParallel(local_cluster)

## Finding # of topics
tuning = FindTopicsNumber(io_dtm,
                          topics = seq(2, 20, 1),
                          metrics = c("Griffiths2004",
                                       "CaoJuan2009",
                                       "Arun2010",
                                       "Deveaud2014"),
                          control = list(seed = 2023),
                          verbose = TRUE)
FindTopicsNumber_plot(tuning)

## Turning off parallelization
stopCluster(local_cluster)
registerDoSEQ()
```

#### 2. Fitting topic model with k = 6
```{r build_lda}
# Actual fitting of LDA model 
lda_results = LDA(io_dtm, 6,
                  control = list(seed = 2023))

## Posterior probabilities representing the probability that a word belongs to a topic
lda_betas = tidy(lda_results, matrix = "beta")

## Posterior probabilities of documents about each topic
lda_gammas = tidy(lda_results, matrix = "gamma")
```


#### 3. Exploring the beta matrix 

Q1. Using the beta matrix alone, what topics would you conclude your final topic list maps onto? (e.g., topic 1, 2, 3…n each reflect what substantive topic construct? Use your best judgment.)
\n 

* In response to question 1, based on the terms that have the highest posterior probabilities of representing the probability that a word belongs to a topic. I think each of my 6 topics will map onto the following concepts. However, there is a decent amount of content overlap between topics in terms of content, e.g., topic 3 "miscellaneous questions about IO Psychology" virtually overlaps with all other topics. 

\n 
1) Master's degree specific questions \n
2) Asking for career-related help (e.g., whether one should get an IO master's and advice for working in people analytics) \n
3) Miscellaneous questions about IO Psychology (e.g., the role of AI/ML in IO and book recommendations) \n
4) IO Psychology jobs (e.g., availability of consulting jobs in IO and asking for raises/ promotions) \n
5) Research, conferences (e.g., SIOP), and questions about IO PhDs \n
6) Thoughts and discussions on IO-related topics (e.g., "what have you been reading and what do you think of it?") \n


```{r}
# Building beta matrix to visualize the top 10 terms associated with each topic
lda_betas %>%
  group_by(topic) %>% 
  top_n(10, beta) %>% 
  arrange(topic, -beta) 

topic_names = data.frame(topic = 1:6,
                          assigned_topic_names = c("Master's degree specific questions",
                                                   "Asking for career-related help",
                                                   "Miscellaneous questions about IO Psychology",
                                                   "IO Psychology Jobs",
                                                   "Research, conferences, and questions relaed to IO PhDs",
                                                   "Thoughts and discussions on IO-related topics"))
```


#### 4. Creating required tibble "topics_tbl" 

Q2. Look at the original text of documents with the highest and lowest probabilities assigned to each document. Do your topic names derived from your interpretation of the beta matrix conceptually match with the content of the original posts? What kind of validity evidence does your answer to this question represent?

\n
* Based on the output below, we can see that topic names derived from my interpretation of the beta matrix conceptually match with the content of the original posts to some degree but not perfectly. For example, document 11 "IO or HRM masters?" is correctly mapped onto topic 1 " master's degree specific questions" but document 18 "Harvard business review" is incorrectly mapped onto topic 1 when it should have been classified into topics 3 or 5. 

\n

* My answer to this question represents content validity in that each topic (construct) grouping is determined based on the content of the post titles.   
```{r topics_tbl}
# Creating required tibble "topics_tbl"

## First getting only the posts used in DTM using the logical vector I defined
## above to track which posts were filtered out
post_titles = week12_tbl %>% filter(post_retained) %>% 
  pull(post)

topics_tbl = lda_gammas %>% group_by(document) %>% 
  top_n(1, gamma) %>%
  slice(1) %>%
  ungroup() %>% 
  mutate(document = as.numeric(document)) %>% 
  arrange(document) %>%
  mutate(original = post_titles) %>% 
  rename(doc_id = document, 
         probability = gamma) %>% 
  select(doc_id, original, topic, probability) # %>% 
 # left_join(topic_names, by = "topic") # this is for me to look at topic groupings more easily 
topics_tbl 
```

#### 5. Creating required tibble "final_tbl" 

```{r final_tbl}
# Creating required tibble "final_tbl"
upvotes_filtered = week12_tbl[topics_tbl$doc_id, "upvotes"]$upvotes

final_tbl = topics_tbl %>% 
  mutate(upvotes = upvotes_filtered,
         topic = factor(topic, ordered = FALSE))
final_tbl
```

#### 6. Analyzing the relationship between upvotes and topic number

* To determine whether upvotes differ by topic, I ran an anova with topic number as the grouping variable and number of upvotes as the dependent variable. Results show that the group means for the number of upvotes across topics did not significantly differ from each other, *F* = 1.661 and *p* = 0.15 > 0.05. 
```{r upvotes_by_topic}
# Running statistical analysis to determine if upvotes differs by topic
## Anova (this)
anova_mod = aov(upvotes ~ topic, data = final_tbl)
summary(anova_mod) # 1 observation dropped due to missingness because the post was too early and upvote number was hidden with a dot at the time of scraping
```

\

# Visualization

## Creating a wordcloud of io_dtm
* Based on the wordcloud below, we can see the most frequent terms occurring in all of reddit posts from the IO subreddit, terms such as "master", "research", "career", "work", "job", "read", and "think" are most common, indicating that a big portion of the reddit posts are about these topics/ actions. 
```{r}
m = as.matrix(io_dtm) 
wordcloud(words = colnames((m)),
          freq = colSums(m),
          min.freq = 1, max.words = 50,
         # scale=c(0.5, 1.5),
          colors = c("#f29d35", "#f24b99"))
```

\n
\n
\n
\n

# Resources 
* This section contains links or forums I consulted to solve rJava problem related to library "qdap" on a Macbook M1 
```{r}
# reference this: https://stackoverflow.com/questions/67849830/how-to-install-rjava-package-in-mac-with-m1-architecture
#https://stackoverflow.com/questions/46513639/how-to-downgrade-java-from-9-to-8-on-a-macos-eclipse-is-not-running-with-java-9
```

